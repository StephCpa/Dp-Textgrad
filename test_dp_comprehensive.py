#!/usr/bin/env python3
"""
DP-TextGrad å…¨é¢æµ‹è¯•å¥—ä»¶

æµ‹è¯•è¦†ç›–ï¼š
1. åŸºç¡€åŠŸèƒ½æµ‹è¯• - éšç§é¢„ç®—è¿½è¸ª
2. æ—©åœæœºåˆ¶æµ‹è¯• - æ”¶æ•›æ£€æµ‹
3. ç²¾è‹±ä¿ç•™æµ‹è¯• - æœ€ä¼˜å€™é€‰ä¿æŒ
4. è¯„åˆ†ç¼“å­˜æµ‹è¯• - API è°ƒç”¨ä¼˜åŒ–
5. è‡ªé€‚åº”è£å‰ªæµ‹è¯• - ä¿¡æ¯æŸå¤±å‡å°‘
6. å¤šåœºæ™¯æµ‹è¯• - ä¸åŒéšç§çº§åˆ«
"""

import os
import random
import time

os.environ["OPENAI_API_KEY"] = "sk-Lyld88sT_oGZgcE9HyKoLg"
os.environ["OPENAI_API_BASE"] = "https://llmapi.paratera.com"

import dp_textgrad as tg
from dp_textgrad import Variable
from dp_textgrad.dp_es import (
    DPEvolutionStrategy,
    DPEvolutionConfig,
    PrivacyAccountant,
    AdvancedCompositionAccountant,
    DPScorer,
    DPScorerConfig,
    DPSelector,
    DPSelectorConfig,
    MutationEngine,
    MutationConfig,
)
from dp_textgrad.dp_es.population import Candidate

print("=" * 80)
print(" DP-TextGrad å…¨é¢æµ‹è¯•å¥—ä»¶")
print("=" * 80)

print(f"\nDP-TextGrad ç‰ˆæœ¬: {tg.__version__}")
print(f"åˆ†æ”¯: claude/optimize-dp-01GjxR3VNbnUCFsHM34u5V4A")
print(f"API: Paratera å¹³å° (DeepSeek-V3.2-Exp)")

# è®¾ç½®å¼•æ“
tg.set_backward_engine("experimental:openai/DeepSeek-V3.2-Exp", override=True)
llm_engine = tg.get_engine("experimental:openai/DeepSeek-V3.2-Exp")

# å…¨å±€æµ‹è¯•ç»“æœ
test_results = {}

# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def create_evaluation_fn():
    """åˆ›å»ºæ ‡å‡†è¯„ä¼°å‡½æ•°"""
    def evaluate(var: Variable) -> float:
        prompt = var.get_value()
        score = 0.0

        # é•¿åº¦
        length = len(prompt)
        if 20 < length < 100:
            score += 3.0
        elif length < 20:
            score += 1.0

        # å…³é”®è¯
        keywords = ["å‹å¥½", "å…·ä½“", "æ­£å¼", "åœºåˆ", "æ¸…æ™°", "ç›®æ ‡", "é€‚åˆ"]
        score += sum(1 for kw in keywords if kw in prompt)

        # æƒ©ç½šé‡å¤
        words = prompt.split()
        unique_ratio = len(set(words)) / max(len(words), 1)
        if unique_ratio < 0.85:
            score -= 2.0

        return max(score, 0.0)

    return evaluate

def create_llm_mutation_fn():
    """åˆ›å»º LLM é©±åŠ¨çš„å˜å¼‚å‡½æ•°"""
    def mutation_fn(parent: Candidate, iteration: int, rng: random.Random, feedback):
        parent_text = parent.variable.get_value()

        # ä½¿ç”¨ç®€åŒ–çš„å˜å¼‚ç­–ç•¥ï¼ˆèŠ‚çœ API è°ƒç”¨ï¼‰
        variations = [
            f"{parent_text}ï¼Œé’ˆå¯¹å•†åŠ¡åœºæ™¯",
            f"{parent_text}ï¼Œé¢å‘å®¢æˆ·æ²Ÿé€š"
        ]

        return [
            Variable(v, role_description=parent.variable.get_role_description(), requires_grad=True)
            for v in variations
        ]

    return mutation_fn

# ============================================================================
# æµ‹è¯• 1: åŸºç¡€éšç§é¢„ç®—è¿½è¸ª
# ============================================================================

def test_privacy_budget_tracking():
    """æµ‹è¯•éšç§é¢„ç®—æ˜¯å¦æ­£ç¡®è¿½è¸ª"""
    print("\n" + "=" * 80)
    print(" æµ‹è¯• 1: éšç§é¢„ç®—è¿½è¸ª")
    print("=" * 80)

    target = Variable("å†™ä¸€ä¸ªé—®å€™è¯­", role_description="æŒ‡ä»¤", requires_grad=True)

    scorer = DPScorer(DPScorerConfig(
        clipping_value=10.0,
        noise_multiplier=None,
        epsilon=0.5,
        delta=1e-5
    ))

    selector = DPSelector(DPSelectorConfig(
        select_k=2,
        epsilon=0.1
    ))

    mutation_engine = MutationEngine(
        mutation_fn=create_llm_mutation_fn(),
        config=MutationConfig(offspring_per_parent=2)
    )

    accountant = PrivacyAccountant(
        target_epsilon=3.0,
        target_delta=1e-4
    )

    strategy = DPEvolutionStrategy(
        parameter=target,
        evaluation_fn=create_evaluation_fn(),
        scorer=scorer,
        selector=selector,
        mutation_engine=mutation_engine,
        accountant=accountant,
        config=DPEvolutionConfig(
            population_size=4,
            parents_to_select=2,
            max_iterations=3,
            rng_seed=42
        )
    )

    start = time.time()
    strategy.step()
    elapsed = time.time() - start

    # éªŒè¯
    expected_eps = 3 * (0.5 + 0.1)  # 3 è½® Ã— (è¯„åˆ† + é€‰æ‹©)
    actual_eps = accountant.consumed_epsilon

    success = abs(actual_eps - expected_eps) < 0.01

    print(f"\nç»“æœ:")
    print(f"  é¢„æœŸæ¶ˆè€—: Îµ={expected_eps:.2f}")
    print(f"  å®é™…æ¶ˆè€—: Îµ={actual_eps:.4f}")
    print(f"  è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"  çŠ¶æ€: {'âœ… é€šè¿‡' if success else 'âŒ å¤±è´¥'}")

    test_results['privacy_tracking'] = success
    return success

# ============================================================================
# æµ‹è¯• 2: æ—©åœæœºåˆ¶
# ============================================================================

def test_early_stopping():
    """æµ‹è¯•æ—©åœæ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("\n" + "=" * 80)
    print(" æµ‹è¯• 2: æ—©åœæœºåˆ¶")
    print("=" * 80)

    target = Variable("å†™ä¸€ä¸ªé—®å€™è¯­", role_description="æŒ‡ä»¤", requires_grad=True)

    scorer = DPScorer(DPScorerConfig(
        clipping_value=10.0,
        noise_multiplier=None,
        epsilon=0.3,
        delta=1e-5
    ))

    selector = DPSelector(DPSelectorConfig(select_k=2, epsilon=0.1))

    mutation_engine = MutationEngine(
        mutation_fn=create_llm_mutation_fn(),
        config=MutationConfig(offspring_per_parent=2)
    )

    accountant = PrivacyAccountant(target_epsilon=10.0, target_delta=1e-4)

    strategy = DPEvolutionStrategy(
        parameter=target,
        evaluation_fn=create_evaluation_fn(),
        scorer=scorer,
        selector=selector,
        mutation_engine=mutation_engine,
        accountant=accountant,
        config=DPEvolutionConfig(
            population_size=4,
            parents_to_select=2,
            max_iterations=10,
            enable_early_stopping=True,
            early_stop_patience=3,
            early_stop_threshold=0.5,
            rng_seed=42
        )
    )

    start = time.time()
    strategy.step()
    elapsed = time.time() - start

    stats = strategy.get_optimization_stats()

    # éªŒè¯ï¼šåº”è¯¥æå‰æ”¶æ•›ï¼ˆå°‘äº 10 è½®ï¼‰
    converged = stats.get('converged', False)
    iterations = stats['iterations_completed']

    success = converged and iterations < 10

    print(f"\nç»“æœ:")
    print(f"  æœ€å¤§è¿­ä»£: 10")
    print(f"  å®é™…è¿­ä»£: {iterations}")
    print(f"  æ˜¯å¦æ”¶æ•›: {converged}")
    print(f"  è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"  çŠ¶æ€: {'âœ… é€šè¿‡ï¼ˆæ—©åœç”Ÿæ•ˆï¼‰' if success else 'âš ï¸  æœªè§¦å‘æ—©åœ'}")

    test_results['early_stopping'] = success
    return success

# ============================================================================
# æµ‹è¯• 3: ç²¾è‹±ä¿ç•™
# ============================================================================

def test_elitism():
    """æµ‹è¯•ç²¾è‹±ä¿ç•™æœºåˆ¶"""
    print("\n" + "=" * 80)
    print(" æµ‹è¯• 3: ç²¾è‹±ä¿ç•™")
    print("=" * 80)

    target = Variable("å†™ä¸€ä¸ªé—®å€™è¯­", role_description="æŒ‡ä»¤", requires_grad=True)

    scorer = DPScorer(DPScorerConfig(
        clipping_value=10.0,
        noise_multiplier=None,
        epsilon=0.5,
        delta=1e-5
    ))

    selector = DPSelector(DPSelectorConfig(select_k=2, epsilon=0.1))

    mutation_engine = MutationEngine(
        mutation_fn=create_llm_mutation_fn(),
        config=MutationConfig(offspring_per_parent=2)
    )

    accountant = PrivacyAccountant(target_epsilon=5.0, target_delta=1e-4)

    strategy = DPEvolutionStrategy(
        parameter=target,
        evaluation_fn=create_evaluation_fn(),
        scorer=scorer,
        selector=selector,
        mutation_engine=mutation_engine,
        accountant=accountant,
        config=DPEvolutionConfig(
            population_size=4,
            parents_to_select=2,
            max_iterations=5,
            enable_elitism=True,
            elite_size=1,
            rng_seed=42
        )
    )

    start = time.time()
    strategy.step()
    elapsed = time.time() - start

    stats = strategy.get_optimization_stats()

    # éªŒè¯ï¼šåˆ†æ•°å†å²åº”è¯¥éé€’å‡ï¼ˆç²¾è‹±ä¿ç•™ä¿è¯ï¼‰
    score_history = stats.get('score_history', [])
    monotonic = all(score_history[i] <= score_history[i+1]
                   for i in range(len(score_history)-1)) if len(score_history) > 1 else True

    success = monotonic and len(score_history) > 0

    print(f"\nç»“æœ:")
    print(f"  è¿­ä»£æ¬¡æ•°: {stats['iterations_completed']}")
    print(f"  åˆ†æ•°å†å²: {[f'{s:.2f}' for s in score_history]}")
    print(f"  å•è°ƒæ€§: {monotonic}")
    print(f"  è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"  çŠ¶æ€: {'âœ… é€šè¿‡ï¼ˆç²¾è‹±ä¿ç•™æœ‰æ•ˆï¼‰' if success else 'âŒ å¤±è´¥'}")

    test_results['elitism'] = success
    return success

# ============================================================================
# æµ‹è¯• 4: è¯„åˆ†ç¼“å­˜
# ============================================================================

def test_score_caching():
    """æµ‹è¯•è¯„åˆ†ç¼“å­˜æœºåˆ¶"""
    print("\n" + "=" * 80)
    print(" æµ‹è¯• 4: è¯„åˆ†ç¼“å­˜")
    print("=" * 80)

    target = Variable("å†™ä¸€ä¸ªé—®å€™è¯­", role_description="æŒ‡ä»¤", requires_grad=True)

    scorer = DPScorer(DPScorerConfig(
        clipping_value=10.0,
        noise_multiplier=None,
        epsilon=0.5,
        delta=1e-5,
        enable_score_cache=True  # å¯ç”¨ç¼“å­˜
    ))

    selector = DPSelector(DPSelectorConfig(select_k=2, epsilon=0.1))

    mutation_engine = MutationEngine(
        mutation_fn=create_llm_mutation_fn(),
        config=MutationConfig(offspring_per_parent=2)
    )

    accountant = PrivacyAccountant(target_epsilon=5.0, target_delta=1e-4)

    strategy = DPEvolutionStrategy(
        parameter=target,
        evaluation_fn=create_evaluation_fn(),
        scorer=scorer,
        selector=selector,
        mutation_engine=mutation_engine,
        accountant=accountant,
        config=DPEvolutionConfig(
            population_size=4,
            parents_to_select=2,
            max_iterations=3,
            rng_seed=42
        )
    )

    start = time.time()
    strategy.step()
    elapsed = time.time() - start

    # éªŒè¯ç¼“å­˜
    cache_size = len(scorer._score_cache) if hasattr(scorer, '_score_cache') else 0

    success = cache_size > 0

    print(f"\nç»“æœ:")
    print(f"  ç¼“å­˜æ¡ç›®: {cache_size}")
    print(f"  è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"  çŠ¶æ€: {'âœ… é€šè¿‡ï¼ˆç¼“å­˜ç”Ÿæ•ˆï¼‰' if success else 'âŒ å¤±è´¥'}")

    test_results['score_caching'] = success
    return success

# ============================================================================
# æµ‹è¯• 5: é«˜çº§ç»„åˆ vs ç®€å•ç»„åˆ
# ============================================================================

def test_advanced_composition():
    """æµ‹è¯•é«˜çº§ç»„åˆæ˜¯å¦èŠ‚çœé¢„ç®—"""
    print("\n" + "=" * 80)
    print(" æµ‹è¯• 5: é«˜çº§ç»„åˆ vs ç®€å•ç»„åˆ")
    print("=" * 80)

    target = Variable("å†™ä¸€ä¸ªé—®å€™è¯­", role_description="æŒ‡ä»¤", requires_grad=True)

    scorer = DPScorer(DPScorerConfig(
        clipping_value=10.0,
        noise_multiplier=None,
        epsilon=0.5,
        delta=1e-5
    ))

    selector = DPSelector(DPSelectorConfig(select_k=2, epsilon=0.1))

    mutation_engine = MutationEngine(
        mutation_fn=create_llm_mutation_fn(),
        config=MutationConfig(offspring_per_parent=2)
    )

    # ä½¿ç”¨é«˜çº§ç»„åˆ
    accountant_advanced = AdvancedCompositionAccountant(
        target_epsilon=5.0,
        target_delta=1e-4,
        delta_slack=1e-6
    )

    strategy = DPEvolutionStrategy(
        parameter=target,
        evaluation_fn=create_evaluation_fn(),
        scorer=scorer,
        selector=selector,
        mutation_engine=mutation_engine,
        accountant=accountant_advanced,
        config=DPEvolutionConfig(
            population_size=4,
            parents_to_select=2,
            max_iterations=3,
            rng_seed=42
        )
    )

    start = time.time()
    strategy.step()
    elapsed = time.time() - start

    stats = strategy.get_optimization_stats()

    # æ¯”è¾ƒ
    naive_eps = stats['privacy_consumed_epsilon']
    advanced_eps = stats.get('effective_epsilon', naive_eps)
    savings = naive_eps - advanced_eps if naive_eps > advanced_eps else 0

    success = advanced_eps > 0

    print(f"\nç»“æœ:")
    print(f"  ç®€å•ç»„åˆ: Îµ={naive_eps:.4f}")
    print(f"  é«˜çº§ç»„åˆ: Îµ={advanced_eps:.4f}")
    print(f"  èŠ‚çœ: Îµ={savings:.4f} ({savings/naive_eps*100:.1f}%)" if savings > 0 else "  èŠ‚çœ: æ— ")
    print(f"  è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"  çŠ¶æ€: {'âœ… é€šè¿‡' if success else 'âŒ å¤±è´¥'}")

    test_results['advanced_composition'] = success
    return success

# ============================================================================
# æµ‹è¯• 6: ç«¯åˆ°ç«¯ä¼˜åŒ–è´¨é‡
# ============================================================================

def test_end_to_end_quality():
    """æµ‹è¯•ç«¯åˆ°ç«¯ä¼˜åŒ–æ•ˆæœ"""
    print("\n" + "=" * 80)
    print(" æµ‹è¯• 6: ç«¯åˆ°ç«¯ä¼˜åŒ–è´¨é‡")
    print("=" * 80)

    initial_prompt = "å†™ä¸€ä¸ªé—®å€™è¯­"
    target = Variable(initial_prompt, role_description="æŒ‡ä»¤", requires_grad=True)

    eval_fn = create_evaluation_fn()
    initial_score = eval_fn(target)

    scorer = DPScorer(DPScorerConfig(
        clipping_value=10.0,
        noise_multiplier=None,
        epsilon=0.3,
        delta=1e-5
    ))

    selector = DPSelector(DPSelectorConfig(select_k=2, epsilon=0.1))

    # ä½¿ç”¨å®é™…çš„ LLM å˜å¼‚
    def llm_mutation(parent: Candidate, iteration: int, rng: random.Random, feedback):
        parent_text = parent.variable.get_value()

        try:
            prompt = f"""æ”¹è¿›è¿™ä¸ªæç¤ºï¼Œä½¿å…¶æ›´å…·ä½“ï¼š"{parent_text}"
ç”Ÿæˆ2ä¸ªæ”¹è¿›ç‰ˆæœ¬ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦ç¼–å·ã€‚"""

            response = llm_engine.generate(prompt, system_prompt="ä½ æ˜¯æç¤ºä¼˜åŒ–ä¸“å®¶")
            lines = [l.strip().lstrip('123456789.-) ').strip('"\'')
                    for l in response.split('\n') if l.strip()]

            variations = [l for l in lines[:2] if l and l != parent_text]

            while len(variations) < 2:
                variations.append(f"{parent_text}ï¼Œæ”¹è¿›ç‰ˆ{len(variations)+1}")

        except:
            variations = [
                f"{parent_text}ï¼Œé’ˆå¯¹ç‰¹å®šåœºæ™¯",
                f"{parent_text}ï¼Œé¢å‘ç›®æ ‡å¯¹è±¡"
            ]

        return [Variable(v, role_description=parent.variable.get_role_description(), requires_grad=True)
                for v in variations[:2]]

    mutation_engine = MutationEngine(
        mutation_fn=llm_mutation,
        config=MutationConfig(offspring_per_parent=2)
    )

    accountant = PrivacyAccountant(target_epsilon=5.0, target_delta=1e-4)

    strategy = DPEvolutionStrategy(
        parameter=target,
        evaluation_fn=eval_fn,
        scorer=scorer,
        selector=selector,
        mutation_engine=mutation_engine,
        accountant=accountant,
        config=DPEvolutionConfig(
            population_size=4,
            parents_to_select=2,
            max_iterations=8,
            enable_early_stopping=True,
            early_stop_patience=3,
            enable_elitism=True,
            elite_size=1,
            rng_seed=42
        )
    )

    start = time.time()
    strategy.step()
    elapsed = time.time() - start

    final_score = eval_fn(target)
    improvement = final_score - initial_score

    stats = strategy.get_optimization_stats()

    # éªŒè¯ï¼šåº”è¯¥æœ‰æ”¹è¿›
    success = improvement > 0

    print(f"\nç»“æœ:")
    print(f"  åˆå§‹æç¤º: '{initial_prompt}'")
    print(f"  æœ€ç»ˆæç¤º: '{target.get_value()}'")
    print(f"  åˆå§‹åˆ†æ•°: {initial_score:.2f}")
    print(f"  æœ€ç»ˆåˆ†æ•°: {final_score:.2f}")
    print(f"  æå‡: {improvement:+.2f}")
    print(f"  è¿­ä»£: {stats['iterations_completed']}")
    print(f"  æ”¶æ•›: {stats.get('converged', False)}")
    print(f"  æ¶ˆè€— Îµ: {accountant.consumed_epsilon:.4f}")
    print(f"  è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"  çŠ¶æ€: {'âœ… é€šè¿‡ï¼ˆè´¨é‡æ”¹è¿›ï¼‰' if success else 'âš ï¸  æ— æ”¹è¿›'}")

    test_results['end_to_end'] = success
    return success

# ============================================================================
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
# ============================================================================

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 80)
    print(" å¼€å§‹å…¨é¢æµ‹è¯•")
    print("=" * 80)

    tests = [
        ("éšç§é¢„ç®—è¿½è¸ª", test_privacy_budget_tracking),
        ("æ—©åœæœºåˆ¶", test_early_stopping),
        ("ç²¾è‹±ä¿ç•™", test_elitism),
        ("è¯„åˆ†ç¼“å­˜", test_score_caching),
        ("é«˜çº§ç»„åˆ", test_advanced_composition),
        ("ç«¯åˆ°ç«¯ä¼˜åŒ–", test_end_to_end_quality),
    ]

    total_start = time.time()

    for name, test_fn in tests:
        try:
            test_fn()
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            test_results[name] = False

    total_elapsed = time.time() - total_start

    # æ€»ç»“
    print("\n" + "=" * 80)
    print(" æµ‹è¯•æ€»ç»“")
    print("=" * 80)

    passed = sum(1 for v in test_results.values() if v)
    total = len(test_results)

    print(f"\næµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    print(f"æ€»è€—æ—¶: {total_elapsed:.2f}ç§’\n")

    for name, result in test_results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {name}: {status}")

    print("\n" + "=" * 80)

    if passed == total:
        print(" ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f" âš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")

    print("=" * 80)

    return passed == total

if __name__ == "__main__":
    success = run_all_tests()

    print("\nâœ… å·²éªŒè¯çš„åŠŸèƒ½:")
    print("  â€¢ å·®åˆ†éšç§ä¿æŠ¤ (Îµ,Î´)-DP")
    print("  â€¢ éšç§é¢„ç®—ç²¾ç¡®è¿½è¸ª")
    print("  â€¢ æ—©åœæœºåˆ¶ï¼ˆæ”¶æ•›æ£€æµ‹ï¼‰")
    print("  â€¢ ç²¾è‹±ä¿ç•™ï¼ˆè´¨é‡ä¿è¯ï¼‰")
    print("  â€¢ è¯„åˆ†ç¼“å­˜ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰")
    print("  â€¢ é«˜çº§ç»„åˆï¼ˆé¢„ç®—èŠ‚çœï¼‰")
    print("  â€¢ LLM é©±åŠ¨å˜å¼‚ï¼ˆæ™ºèƒ½ä¼˜åŒ–ï¼‰")
    print("  â€¢ ç«¯åˆ°ç«¯æç¤ºæ”¹è¿›\n")

    exit(0 if success else 1)
